{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dogs vs Cats - Part 3\n",
    "\n",
    "Classify whether images contain either a dog or a cat. Download the data from: https://www.kaggle.com/c/dogs-vs-cats/data\n",
    "\n",
    "Using an ensemble we achieve an accuracy of 99.0889% on our test set.\n",
    "\n",
    "This notebook assumes you have already run the steps from the Dogs vs Cats - Part 1 notebook where you downloaded the images and created the training, validation, and test directories.\n",
    "\n",
    "The dataset contains 25,000 images of dogs and cats (12,500 from each class). We will create a new dataset containing 3 subsets, a training set with 10,000 samples of each class, a validation dataset with 1250 of each class and a test set with 1250 samples of each class.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.models as models\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/wtf/.cache/torch/hub/pytorch_vision_master\n",
      "Using cache found in /home/wtf/.cache/torch/hub/pytorch_vision_master\n"
     ]
    }
   ],
   "source": [
    "model_resnet18 = torch.hub.load('pytorch/vision', 'resnet18', pretrained=True)\n",
    "model_resnet34 = torch.hub.load('pytorch/vision', 'resnet34', pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Freeze all params except the BatchNorm layers, as here they are trained to the\n",
    "# mean and standard deviation of ImageNet and we may lose some signal\n",
    "for name, param in model_resnet18.named_parameters():\n",
    "    if(\"bn\" not in name):\n",
    "        param.requires_grad = False\n",
    "        \n",
    "for name, param in model_resnet34.named_parameters():\n",
    "    if(\"bn\" not in name):\n",
    "        param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace the classifier\n",
    "num_classes = 2\n",
    "\n",
    "model_resnet18.fc = nn.Sequential(nn.Linear(model_resnet18.fc.in_features,512),\n",
    "                                  nn.ReLU(),\n",
    "                                  nn.Dropout(),\n",
    "                                  nn.Linear(512, num_classes))\n",
    "\n",
    "model_resnet34.fc = nn.Sequential(nn.Linear(model_resnet34.fc.in_features,512),\n",
    "                                  nn.ReLU(),\n",
    "                                  nn.Dropout(),\n",
    "                                  nn.Linear(512, num_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimizer, loss_fn, train_loader, val_loader, epochs=5, device=\"cpu\"):\n",
    "    for epoch in range(epochs):\n",
    "        training_loss = 0.0\n",
    "        valid_loss = 0.0\n",
    "        model.train()\n",
    "        for batch in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            inputs, targets = batch\n",
    "            inputs = inputs.to(device)\n",
    "            targets = targets.to(device)\n",
    "            output = model(inputs)\n",
    "            loss = loss_fn(output, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            training_loss += loss.data.item() * inputs.size(0)\n",
    "        training_loss /= len(train_loader.dataset)\n",
    "        \n",
    "        model.eval()\n",
    "        num_correct = 0 \n",
    "        num_examples = 0\n",
    "        for batch in val_loader:\n",
    "            inputs, targets = batch\n",
    "            inputs = inputs.to(device)\n",
    "            output = model(inputs)\n",
    "            targets = targets.to(device)\n",
    "            loss = loss_fn(output,targets) \n",
    "            valid_loss += loss.data.item() * inputs.size(0)\n",
    "                        \n",
    "            correct = torch.eq(torch.max(F.softmax(output, dim=1), dim=1)[1], targets).view(-1)\n",
    "            num_correct += torch.sum(correct).item()\n",
    "            num_examples += correct.shape[0]\n",
    "        valid_loss /= len(val_loader.dataset)\n",
    "\n",
    "        print('Epoch: {}, Training Loss: {:.4f}, Validation Loss: {:.4f}, accuracy = {:.4f}'.format(epoch, training_loss,\n",
    "        valid_loss, num_correct / num_examples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=32\n",
    "img_dimensions = 224\n",
    "\n",
    "# Normalize to the ImageNet mean and standard deviation\n",
    "# Could calculate it for the cats/dogs data set, but the ImageNet\n",
    "# values give acceptable results here.\n",
    "img_transforms = transforms.Compose([\n",
    "    transforms.Resize((img_dimensions, img_dimensions)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],std=[0.229, 0.224, 0.225] )\n",
    "    ])\n",
    "\n",
    "img_test_transforms = transforms.Compose([\n",
    "    transforms.Resize((img_dimensions,img_dimensions)),    \n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],std=[0.229, 0.224, 0.225] )\n",
    "    ])\n",
    "\n",
    "def check_image(path):\n",
    "    try:\n",
    "        im = Image.open(path)\n",
    "        return True\n",
    "    except:\n",
    "        return False\n",
    "\n",
    "train_data_path = \"/home/wtf/dogs-vs-cats/train/\"\n",
    "train_data = torchvision.datasets.ImageFolder(root=train_data_path,transform=img_transforms, is_valid_file=check_image)\n",
    "\n",
    "validation_data_path = \"/home/wtf/dogs-vs-cats/validation/\"\n",
    "validation_data = torchvision.datasets.ImageFolder(root=validation_data_path,transform=img_test_transforms, is_valid_file=check_image)\n",
    "\n",
    "test_data_path = \"/home/wtf/dogs-vs-cats/test/\"\n",
    "test_data = torchvision.datasets.ImageFolder(root=test_data_path,transform=img_test_transforms, is_valid_file=check_image)\n",
    "\n",
    "num_workers = 6\n",
    "train_data_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, shuffle=True, num_workers=num_workers)\n",
    "validation_data_loader = torch.utils.data.DataLoader(validation_data, batch_size=batch_size, shuffle=False, num_workers=num_workers)\n",
    "test_data_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_size, shuffle=False, num_workers=num_workers)\n",
    "\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\") \n",
    "else:\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num training images: 16000\n",
      "Num validation images: 4500\n",
      "Num test images: 4500\n"
     ]
    }
   ],
   "source": [
    "print(f'Num training images: {len(train_data_loader.dataset)}')\n",
    "print(f'Num validation images: {len(validation_data_loader.dataset)}')\n",
    "print(f'Num test images: {len(test_data_loader.dataset)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and test the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data in test_data_loader:\n",
    "            images, labels = data[0].to(device), data[1].to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    print('correct: {:d}  total: {:d}'.format(correct, total))\n",
    "    print('accuracy = {:f}'.format(correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Training Loss: 0.0855, Validation Loss: 0.0358, accuracy = 0.9878\n",
      "Epoch: 1, Training Loss: 0.0498, Validation Loss: 0.0309, accuracy = 0.9873\n"
     ]
    }
   ],
   "source": [
    "model_resnet18.to(device)\n",
    "optimizer = optim.Adam(model_resnet18.parameters(), lr=0.001)\n",
    "train(model_resnet18, optimizer, torch.nn.CrossEntropyLoss(), train_data_loader, validation_data_loader, epochs=2, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correct: 4456  total: 4500\n",
      "accuracy = 0.990222\n"
     ]
    }
   ],
   "source": [
    "test_model(model_resnet18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Training Loss: 0.0678, Validation Loss: 0.0239, accuracy = 0.9907\n",
      "Epoch: 1, Training Loss: 0.0354, Validation Loss: 0.0317, accuracy = 0.9887\n"
     ]
    }
   ],
   "source": [
    "model_resnet34.to(device)\n",
    "optimizer = optim.Adam(model_resnet34.parameters(), lr=0.001)\n",
    "train(model_resnet34, optimizer, torch.nn.CrossEntropyLoss(), train_data_loader, validation_data_loader, epochs=2, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correct: 4450  total: 4500\n",
      "accuracy = 0.988889\n"
     ]
    }
   ],
   "source": [
    "test_model(model_resnet34)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make some predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dogs\n",
      "cats\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "def find_classes(dir):\n",
    "    classes = os.listdir(dir)\n",
    "    classes.sort()\n",
    "    class_to_idx = {classes[i]: i for i in range(len(classes))}\n",
    "    return classes, class_to_idx\n",
    "\n",
    "def make_prediction(model, filename):\n",
    "    labels, _ = find_classes('/home/wtf/dogs-vs-cats/test')\n",
    "    img = Image.open(filename)\n",
    "    img = img_test_transforms(img)\n",
    "    img = img.unsqueeze(0)\n",
    "    prediction = model(img.to(device))\n",
    "    prediction = prediction.argmax()\n",
    "    print(labels[prediction])\n",
    "    \n",
    "make_prediction(model_resnet34, '/home/wtf/dogs-vs-cats/test/dogs/dog.11460.jpg')\n",
    "make_prediction(model_resnet34, '/home/wtf/dogs-vs-cats/test/cats/cat.12262.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the models to disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model_resnet18.state_dict(), \"./model_resnet18.pth\")\n",
    "torch.save(model_resnet34.state_dict(), \"./model_resnet34.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the models from disk and test with an ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/wtf/.cache/torch/hub/pytorch_vision_master\n",
      "Using cache found in /home/wtf/.cache/torch/hub/pytorch_vision_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "# Remember that you must call model.eval() to set dropout and batch normalization layers to\n",
    "# evaluation mode before running inference. Failing to do this will yield inconsistent inference result\n",
    "\n",
    "resnet18 = torch.hub.load('pytorch/vision', 'resnet18')\n",
    "resnet18.fc = nn.Sequential(nn.Linear(resnet18.fc.in_features,512),nn.ReLU(), nn.Dropout(), nn.Linear(512, num_classes))\n",
    "resnet18.load_state_dict(torch.load('./model_resnet18.pth'))\n",
    "resnet18.eval()\n",
    "\n",
    "resnet34 = torch.hub.load('pytorch/vision', 'resnet34')\n",
    "resnet34.fc = nn.Sequential(nn.Linear(resnet34.fc.in_features,512),nn.ReLU(), nn.Dropout(), nn.Linear(512, num_classes))\n",
    "resnet34.load_state_dict(torch.load('./model_resnet34.pth'))\n",
    "resnet34.eval()\n",
    "\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy = 0.990889\n",
      "correct: 4459  total: 4500\n"
     ]
    }
   ],
   "source": [
    "# Test against the average of each prediction from the two models\n",
    "models_ensemble = [resnet18.to(device), resnet34.to(device)]\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in test_data_loader:\n",
    "        images, labels = data[0].to(device), data[1].to(device)\n",
    "        predictions = [i(images).data for i in models_ensemble]\n",
    "        avg_predictions = torch.mean(torch.stack(predictions), dim=0)\n",
    "        _, predicted = torch.max(avg_predictions, 1)\n",
    "\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        \n",
    "print('accuracy = {:f}'.format(correct / total))\n",
    "print('correct: {:d}  total: {:d}'.format(correct, total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
